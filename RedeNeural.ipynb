{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef4b92-c5e1-41d3-8139-711389a24163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1ecab6-85b5-4b4a-a5be-059499807a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f0489-a3e1-4a57-8c50-fc262ab35ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = datasets.make_moons(n_samples=500,noise=0.05)\n",
    "x.shape,y.shape\n",
    "\n",
    "print(f'{x.shape= }, {y.shape= }')\n",
    "\n",
    "pd.DataFrame({'x_1':x[:,0],'x_2':x[:,1],'y':y})\n",
    "\n",
    "unique = np.unique(y, return_counts=True)\n",
    "for label,qt_label in zip(unique[0],unique[1]):\n",
    "    print(f'Label: {label}\\t Counts: {qt_label= }') \n",
    "\n",
    "plt.scatter(x[:,0],x[:,1],c=y,s=50,alpha=0.5,cmap='cool')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b37e1-1f09-47dd-99a5-0708adf59dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NnModel:\n",
    "    def __init__(self,x:np.ndarray,y:np.ndarray,hidden_neurons:int=10,output_neurons:int=2):\n",
    "        np.random.seed(8)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        self.output_neurons = output_neurons\n",
    "        self.input_neurons = self.x.shape[1]\n",
    "        \n",
    "        #inicializando pesos e bias\n",
    "        #Xavier Initialization -> variancia dos pesos iguais em todas as camadas\n",
    "        self.W1 = np.random.randn(self.input_neurons,self.hidden_neurons) / np.sqrt(self.input_neurons)\n",
    "        self.B1 = np.zeros((1,self.hidden_neurons))\n",
    "        self.W2 = np.random.randn(self.hidden_neurons,self.output_neurons) / np.sqrt(self.hidden_neurons)\n",
    "        self.B2 = np.zeros((1,self.output_neurons))\n",
    "        self.model_dict = {'W1': self.W1,'B1': self.B1,'W2': self.W2,'B2': self.B2}\n",
    "        self.z1 = 0\n",
    "        self.f1 = 0  \n",
    "    def foward(self,x:np.ndarray) -> np.ndarray:\n",
    "        #eq da reta\n",
    "        self.z1 = x.dot(self.W1) + self.B1\n",
    "        #função de ativação\n",
    "        self.f1 = np.tanh(self.z1)\n",
    "        #eq da reta 2\n",
    "        z2 = self.f1.dot(self.W2) + self.B2\n",
    "\n",
    "        exp_values = np.exp(z2)\n",
    "        softmax = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        return softmax\n",
    "    def loss(self, softmax):\n",
    "        #Cross Entropy - calcular a perda para classe correta\n",
    "        predictions = np.zeros(self.y.shape[0]) \n",
    "        for i, correct_index in enumerate(self.y):\n",
    "            predicted = softmax[i][correct_index]\n",
    "            predictions[i] = predicted\n",
    "        log_probs = -np.log(predictions)\n",
    "        return log_probs/self.yshape[0]\n",
    "    def backpropagation(self,softmax:np.ndarray,learning_rate:float)->None:\n",
    "        delta2 = np.copy(softmax)\n",
    "        delta2[range(x.shape[0]),y] -= 1\n",
    "        dW2 = (self.f1.T).dot(delta2)\n",
    "        dB2 = np.sum(delta2, axis=0, keepdims=True)\n",
    "        delta1 = delta2.dot(self.W2.T) * (1 - np.power(np.tanh(self.z1), 2 ))\n",
    "        dW1 = (x.T).dot(delta1)\n",
    "        dB1 = np.sum(delta1, axis=0, keepdims=True)\n",
    "        \n",
    "        #atualiando pesos e bias\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.B1 -= learning_rate * dB1\n",
    "        self.B2 -= learning_rate * dB2\n",
    "        \n",
    "    def fit(self):\n",
    "        pass    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d239a1-7eb7-4aca-8e9f-842918ce7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = NnModel(x,y,10,2)\n",
    "softmax = modelo.foward(x)\n",
    "modelo.loss(softmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
